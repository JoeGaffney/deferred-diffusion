{"openapi":"3.1.0","info":{"title":"API","version":"0.1.0"},"paths":{"/api/images/local/{model}":{"post":{"tags":["Images"],"summary":"Create Local","description":"# Generate images using various diffusion models.\n- External models are processed through their respective APIs.\n- Local models are processed on your own GPU workers.\n- ControlNets and Adapters are unified as **references**.\n## sd-xl\n\nStable Diffusion XL variant supports the most control nets and IP adapters. It excels at generating high-quality, detailed images with complex prompts and multiple subjects.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✓\n\n## sd-3\n\nStable Diffusion 3.5 offers superior prompt understanding and composition. Excels at complex scenes, concept art, and handling multiple subjects with accurate interactions.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✗\n\n## flux-1\n\nFLUX Krea model is flux-1 dev trained with opinions from krea for more photorealistic results. Will use flux Kontext for image to image and flux fill for inpainting.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✓\n\n## qwen-image\n\nQwen model specializes in generating high-quality images from textual descriptions. It excels at understanding nuanced prompts and delivering detailed visuals.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✓\n\n## depth-anything-2\n\nAdvanced depth estimation model. Creates high-quality depth maps from any image for 3D visualization, AR applications, and as input for ControlNet pipelines.\n- **Text (text-to-image):** ✗\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✗\n\n## segment-anything-2\n\nState-of-the-art image segmentation model. Precisely identifies and segments objects, people, and features for compositing, editing, and analysis.\n- **Text (text-to-image):** ✗\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✗","operationId":"images_create_local","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["sd-xl","sd-3","flux-1","qwen-image","depth-anything-2","segment-anything-2","real-esrgan-x4"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/images/external/{model}":{"post":{"tags":["Images"],"summary":"Create External","description":"# Generate images using various diffusion models.\n- External models are processed through their respective APIs.\n- Local models are processed on your own GPU workers.\n- ControlNets and Adapters are unified as **references**.\n## gpt-image-1\n\nOpenAI's advanced image generation model with exceptional understanding of complex prompts. Excels at photorealistic imagery, accurate object rendering, and following detailed instructions.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✓\n\n## runway-gen4-image\n\nRunway's Gen-4 image model delivering high-fidelity results with strong coherence. Particularly good at combinging multiple references into a single, cohesive image.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✓\n\n## flux-1-pro\n\nPro variants of FLUX 1.1 with enhanced capabilities. Will use flux Kontext pro for image to image and flux fill pro for inpainting.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✗\n\n## topazlabs-upscale\n\nTopaz Labs' advanced image upscaling model. Specializes in enhancing image resolution while preserving fine details and textures, ideal for professional photography and print work.\n- **Text (text-to-image):** ✗\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✗\n\n## google-gemini-2\n\nGoogle's Gemini 2.5 model for advanced image generation and manipulation. Aka nano bannana\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✓\n\n## bytedance-seedream-4\n\nSupreme image to image context model from Bytedance. Excels at transforming input images based on textual prompts while maintaining core elements of the original image.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✓","operationId":"images_create_external","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["gpt-image-1","runway-gen4-image","flux-1-pro","topazlabs-upscale","google-gemini-2","bytedance-seedream-4"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/images/{id}":{"get":{"tags":["Images"],"summary":"Get","operationId":"images_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/texts/local/{model}":{"post":{"tags":["Texts"],"summary":"Create Local","description":"# Generate text using various language models.\n- External models are processed through their respective APIs.\n- Temperature controls randomness: lower values (0.1-0.3) for focused responses, higher values (0.7-1.0) for creative output.\n- Messages support conversation context with role-based structure (system, user, assistant).\n- Image and video references can be included for multimodal processing (where supported).\n## qwen-2\n\nQwen-2 is a high-performance language model optimized for text generation and conversation. Excels at reasoning, creative writing, and multi-turn conversations.","operationId":"texts_create_local","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"const":"qwen-2","type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/texts/external/{model}":{"post":{"tags":["Texts"],"summary":"Create External","description":"# Generate text using various language models.\n- External models are processed through their respective APIs.\n- Temperature controls randomness: lower values (0.1-0.3) for focused responses, higher values (0.7-1.0) for creative output.\n- Messages support conversation context with role-based structure (system, user, assistant).\n- Image and video references can be included for multimodal processing (where supported).\n## gpt-4o\n\nOpenAI's GPT-4o model with enhanced multimodal capabilities. (mini variant)\n\n## gpt-4\n\nOpenAI's GPT-4 model with advanced reasoning capabilities. (4.1 mini variant)\n\n## gpt-5\n\nOpenAI's latest GPT-5 model with cutting-edge performance across all text generation tasks. (mini variant)","operationId":"texts_create_external","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["gpt-4o","gpt-4","gpt-5"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/texts/{id}":{"get":{"tags":["Texts"],"summary":"Get","operationId":"texts_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos/local/{model}":{"post":{"tags":["Videos"],"summary":"Create Local","description":"# Generate videos using various diffusion models.\n\n# Local Models\n\n### ltx-video\n\nFast but more limted video generation model. Good for quick iterations and less complex scenes.\n\n\n### wan-2\n\nWan 2.2, best open-source video generation model. Good quality and motion coherence for a variety of scenes.","operationId":"videos_create_local","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["ltx-video","wan-2"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos/external/{model}":{"post":{"tags":["Videos"],"summary":"Create External","description":"# Generate videos using various diffusion models.\n\n# External Models\n\n### bytedance-seedance-1\n\nByteDance's Seedance-1 model, Pretty strong overall and quite fast. Good for a variety of video generation tasks with decent quality and speed.\n\n\n### google-veo-3\n\nGoogle's VEO-3 model, high end flagship model. Supports high_quality parameter for slower but higher quality variant.\n\n\n### kwaivgi-kling-2\n\nKling V2 model by kwaivgi, designed for high-quality video generation from text prompts. Known for its ability to create detailed and coherent video sequences.\n\n\n### openai-sora-2\n\nOpenAI's Sora 2 model, high-end video generation model known for producing high-quality and realistic videos from text prompts. Supports high_quality parameter for pro variant. Ideal for professional-grade video content creation.\n\n\n### runway-act-two\n\nRunway's Act Two model updates a video with reference image. Ideal for enhancing existing footage with new visual elements while maintaining original motion and style.\n\n\n### runway-gen-4\n\nRunway's latest Gen-4 showing it's age fast computer time. Good for a variety of video generation tasks with improved quality over Gen-3.\n\n\n### runway-gen-4-aleph\n\nRunway's Gen-4 Aleph model, takes in video input as well as images and can enhance or change the video. Or even generate new video content based on the input images and video. Ideal for creative video transformations and enhancements.\n\n\n### runway-upscale\n\nRunway's Upscale model for high-quality video upscaling. Utilizes advanced techniques to enhance video resolution and detail.","operationId":"videos_create_external","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["runway-gen-4","runway-act-two","runway-upscale","runway-gen-4-aleph","bytedance-seedance-1","kwaivgi-kling-2","google-veo-3","openai-sora-2"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos/{id}":{"get":{"tags":["Videos"],"summary":"Get","operationId":"videos_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/agentic/sequence":{"post":{"tags":["Agentic"],"summary":"Create","operationId":"agentic_sequence_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/SequenceRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/SequenceResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/":{"get":{"summary":"Root","operationId":"root__get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}}},"components":{"schemas":{"CharacterResponse":{"properties":{"name":{"type":"string","title":"Name","description":"Name of the character"},"role":{"type":"string","title":"Role","description":"Role of the character in the scene, e.g., protagonist, antagonist, sidekick"},"gender":{"type":"string","title":"Gender","description":"Gender identity of the character"},"age":{"type":"string","title":"Age","description":"Approximate age or age range"},"ethnicity":{"type":"string","title":"Ethnicity","description":"Ethnic background or appearance of the character"},"height":{"type":"string","title":"Height","description":"Character's height or stature, e.g., tall, short, average"},"build":{"type":"string","title":"Build","description":"Body build of the character, e.g., athletic, lean, bulky"},"eye_color":{"type":"string","title":"Eye Color","description":"Eye color or description"},"hair_color":{"type":"string","title":"Hair Color","description":"Hair color or style"},"profession":{"type":"string","title":"Profession","description":"Character's profession or occupation, if relevant"},"attire":{"type":"string","title":"Attire","description":"Clothing and accessories they wear"},"image_prompt":{"type":"string","title":"Image Prompt","readOnly":true}},"type":"object","required":["name","role","gender","age","ethnicity","height","build","eye_color","hair_color","profession","attire","image_prompt"],"title":"CharacterResponse"},"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"ImageCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"}},"type":"object","required":["id","status"],"title":"ImageCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"ImageRequest":{"properties":{"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Detailed, 8k, photorealistic"},"height":{"type":"integer","title":"Height","default":720},"width":{"type":"integer","title":"Width","default":1280},"seed":{"type":"integer","title":"Seed","default":42},"strength":{"type":"number","title":"Strength","default":0.5},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Optional Base64 image string"},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Optional Base64 image string"},"references":{"items":{"$ref":"#/components/schemas/References"},"type":"array","title":"References","default":[]},"high_quality":{"type":"boolean","title":"High Quality","description":"Use high quality model variant when available (may cost more and take longer). Will use higher steps in local models.","default":false}},"type":"object","title":"ImageRequest"},"ImageResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"},"result":{"anyOf":[{"$ref":"#/components/schemas/ImageWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"ImageResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"ImageWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"ImageWorkerResponse"},"MessageContent":{"properties":{"type":{"type":"string","title":"Type"},"text":{"type":"string","title":"Text","default":""}},"type":"object","required":["type"],"title":"MessageContent"},"MessageItem":{"properties":{"role":{"type":"string","title":"Role"},"content":{"items":{"$ref":"#/components/schemas/MessageContent"},"type":"array","title":"Content"}},"type":"object","required":["role","content"],"title":"MessageItem"},"References":{"properties":{"mode":{"type":"string","enum":["style","style-plus","face","depth","canny","pose"],"title":"Mode"},"strength":{"type":"number","title":"Strength","default":0.5},"image":{"type":"string","contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string"},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Optional Base64 image string"}},"type":"object","required":["mode","image"],"title":"References"},"SceneResponse":{"properties":{"name":{"type":"string","title":"Name","description":"Short name of the scene, e.g., 'forest', 'interior_kitchen'"},"mood":{"type":"string","title":"Mood","description":"Overall mood and atmosphere, e.g., 'mysterious', 'cozy', 'tense'"},"location":{"type":"string","title":"Location","description":"Specific or general location, e.g., 'mountaintop temple', 'urban alleyway'"},"time_of_day":{"type":"string","title":"Time Of Day","description":"Time of day, e.g., 'sunset', 'night', 'early morning'"},"weather":{"type":"string","title":"Weather","description":"Weather or atmospheric conditions, e.g., 'foggy', 'raining', 'clear skies'"},"lighting":{"type":"string","title":"Lighting","description":"Lighting setup, e.g., 'natural sunlight', 'low light', 'dramatic shadows'"},"diffusion_positive_prompt_tags":{"type":"string","title":"Diffusion Positive Prompt Tags","description":"List of prompt tags for image generation, e.g., '4k, DLSR photo, ultra-realistic, soft lighting, cinematic'"},"image_prompt":{"type":"string","title":"Image Prompt","readOnly":true}},"type":"object","required":["name","mood","location","time_of_day","weather","lighting","diffusion_positive_prompt_tags","image_prompt"],"title":"SceneResponse"},"SequenceRequest":{"properties":{"prompt":{"type":"string","title":"Prompt","default":""},"refinement_prompt":{"type":"string","title":"Refinement Prompt","default":""},"scene_reference_image":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Scene Reference Image","description":"Reference image for the scene"},"protagonist_reference_image":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Protagonist Reference Image","description":"Reference image for the protagonist"},"antagonist_reference_image":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Antagonist Reference Image","description":"Reference image for the antagonist"}},"type":"object","title":"SequenceRequest"},"SequenceResponse":{"properties":{"scene":{"$ref":"#/components/schemas/SceneResponse","description":"Description of the scene"},"protagonist":{"anyOf":[{"$ref":"#/components/schemas/CharacterResponse"},{"type":"null"}],"description":"Description of the protagonist"},"antagonist":{"anyOf":[{"$ref":"#/components/schemas/CharacterResponse"},{"type":"null"}],"description":"Description of the antagonist"},"shots":{"items":{"$ref":"#/components/schemas/ShotResponse"},"type":"array","title":"Shots","description":"Sequence of shots in the scene"}},"type":"object","required":["scene","protagonist","antagonist","shots"],"title":"SequenceResponse"},"ShotCharacterResponse":{"properties":{"gender":{"type":"string","title":"Gender","description":"Gender of the character"},"action":{"type":"string","title":"Action","description":"Action of the character in this shot"},"dialog":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Dialog","description":"Dialog of the character in this shot"},"frame_position":{"type":"string","title":"Frame Position","description":"Position of the character in the frame eg. left, right, center"}},"type":"object","required":["gender","action","frame_position"],"title":"ShotCharacterResponse"},"ShotResponse":{"properties":{"name":{"type":"string","title":"Name","description":"Unique identifier name for the shot eg 001, 002"},"antagonist":{"anyOf":[{"$ref":"#/components/schemas/ShotCharacterResponse"},{"type":"null"}],"description":"Description of the antagonist's action and dialog in this shot"},"protagonist":{"anyOf":[{"$ref":"#/components/schemas/ShotCharacterResponse"},{"type":"null"}],"description":"Description of the protagonist's action and dialog in this shot"},"characters":{"type":"string","title":"Characters","description":"Description of the characters in the shot, e.g., 'protagonist character gender and antagonist character gender', 'crowd of people' including their actions and positions"},"subject":{"type":"string","title":"Subject","description":"Description of the subject in the shot, eg. character, character gender. object, environment"},"environment":{"type":"string","title":"Environment","description":"Description of the environment in the shot, eg. castle, forest, interior_kitchen"},"lighting":{"type":"string","title":"Lighting","description":"Description of the lighting in the shot, eg. bright, dark, moody"},"action":{"type":"string","title":"Action","description":"Description of the action taking place in the shot, eg. fight, chase"},"style":{"type":"string","title":"Style","description":"Description of the style of the shot, eg. realistic, cartoon, anime"},"camera_angle":{"type":"string","title":"Camera Angle","description":"Description of the camera angle in the shot, eg. close-up, wide shot"},"camera_movement":{"type":"string","title":"Camera Movement","description":"Description of camera movement and angles eg. pan, tilt, dolly, zoom"},"duration_seconds":{"type":"integer","maximum":300.0,"minimum":1.0,"title":"Duration Seconds","description":"Estimated duration in seconds"},"image_prompt":{"type":"string","title":"Image Prompt","readOnly":true},"video_prompt":{"type":"string","title":"Video Prompt","readOnly":true}},"type":"object","required":["name","antagonist","protagonist","characters","subject","environment","lighting","action","style","camera_angle","camera_movement","duration_seconds","image_prompt","video_prompt"],"title":"ShotResponse"},"TextCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"}},"type":"object","required":["id","status"],"title":"TextCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"TextRequest":{"properties":{"temperature":{"type":"number","title":"Temperature","default":0.7},"seed":{"type":"integer","title":"Seed","default":42},"messages":{"items":{"$ref":"#/components/schemas/MessageItem"},"type":"array","title":"Messages","description":"List of messages","default":[]},"images":{"items":{"type":"string"},"type":"array","title":"Images","description":"Image references","default":[]},"videos":{"items":{"type":"string"},"type":"array","title":"Videos","description":"Video references","default":[]}},"type":"object","title":"TextRequest"},"TextResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"},"result":{"anyOf":[{"$ref":"#/components/schemas/TextWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"TextResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"chain_of_thought":["Step 1","Step 2","Conclusion"],"response":"This is a response from the model"},"status":"SUCCESS"}},"TextWorkerResponse":{"properties":{"response":{"type":"string","title":"Response"},"chain_of_thought":{"items":{},"type":"array","title":"Chain Of Thought"}},"type":"object","required":["response","chain_of_thought"],"title":"TextWorkerResponse"},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"},"VideoCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"}},"type":"object","required":["id","status"],"title":"VideoCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"VideoRequest":{"properties":{"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Slow camera zoom in, 4k, high quality, cinematic, realistic"},"height":{"type":"integer","title":"Height","default":720},"width":{"type":"integer","title":"Width","default":1280},"num_frames":{"type":"integer","title":"Num Frames","default":48},"seed":{"type":"integer","title":"Seed","default":42},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string"},"image_last_frame":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image Last Frame","description":"Optional Base64 image string for the last frame"},"video":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"video/*","title":"Video","description":"Optional Base64 video string for video input"},"high_quality":{"type":"boolean","title":"High Quality","description":"Use high quality model variant when available (may cost more and take longer). Will use higher steps in local models.","default":false}},"type":"object","title":"VideoRequest"},"VideoResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"},"result":{"anyOf":[{"$ref":"#/components/schemas/VideoWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"VideoResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"VideoWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"VideoWorkerResponse"}},"securitySchemes":{"APIKeyHeader":{"type":"apiKey","in":"header","name":"Authorization"}}}}