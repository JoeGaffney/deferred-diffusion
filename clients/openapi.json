{"openapi":"3.1.0","info":{"title":"API","version":"0.1.0"},"paths":{"/api/images":{"post":{"tags":["Images"],"summary":"Create","description":"# Image Models\nExternal models proxy to provider APIs; local models run on your GPU.\n\n| Model | Provider | External | Queue | Modes | References | Description |\n|-------|----------|:--------:|:-----:|-------|:----------:|-------------|\n| sd-xl | local | No | gpu | image-to-image, inpainting, text-to-image | ✓ | Stable Diffusion XL variant with broad adapter/control support. |\n| sd-3 | local | No | gpu | image-to-image, inpainting, text-to-image | ✗ | Stable Diffusion 3.5 for complex compositions. |\n| flux-1 | local | No | gpu | image-to-image, inpainting, text-to-image | ✓ | FLUX dev model (Krea tuned). Uses Kontext for img2img, Fill for inpainting. |\n| qwen-image | local | No | gpu | image-to-image, inpainting, text-to-image | ✓ | Qwen image generation and manipulation. |\n| depth-anything-2 | local | No | gpu | image-to-image | ✗ | Depth estimation pipeline. |\n| segment-anything-2 | local | No | gpu | image-to-image | ✗ | Segmentation pipeline. |\n| gpt-image-1 | openai | Yes | cpu | image-to-image, inpainting, text-to-image | ✓ | OpenAI image model. |\n| runway-gen4-image | runway | Yes | cpu | image-to-image, text-to-image | ✓ | Runway Gen-4 image model. |\n| flux-1-pro | replicate | Yes | cpu | image-to-image, inpainting, text-to-image | ✗ | FLUX 1.1 Pro variants via external provider. |\n| topazlabs-upscale | replicate | Yes | cpu | image-to-image | ✗ | Topaz upscale model. |\n| google-gemini-2 | replicate | Yes | cpu | image-to-image, text-to-image | ✓ | Gemini multimodal image model. |\n| bytedance-seedream-4 | replicate | Yes | cpu | image-to-image, text-to-image | ✓ | Seedream image-to-image context model. |","operationId":"images_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/images/models":{"get":{"tags":["Images"],"summary":"List image models","operationId":"images_list_models","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageModelsResponse"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/images/{id}":{"get":{"tags":["Images"],"summary":"Get","operationId":"images_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"delete":{"tags":["Images"],"summary":"Delete","operationId":"images_delete","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/DeleteResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/texts":{"post":{"tags":["Texts"],"summary":"Create","description":"# Text Models\nExternal models proxy to provider APIs; local models run on your GPU.\n\n| Model | Provider | External | Queue | Description |\n|-------|----------|:--------:|:-----:|-------------|\n| qwen-2 | local | No | gpu | Qwen-2 is a high-performance language model optimized for text generation and conversation. Excels at reasoning, creative writing, and multi-turn conversations. |\n| gpt-4o | openai | Yes | cpu | OpenAI's GPT-4o model with enhanced multimodal capabilities. (mini variant) |\n| gpt-4 | openai | Yes | cpu | OpenAI's GPT-4 model with advanced reasoning capabilities. (4.1 mini variant) |\n| gpt-5 | openai | Yes | cpu | OpenAI's latest GPT-5 model with cutting-edge performance across all text generation tasks. (mini variant) |","operationId":"texts_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/texts/models":{"get":{"tags":["Texts"],"summary":"List text models","operationId":"texts_list_models","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextModelsResponse"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/texts/{id}":{"get":{"tags":["Texts"],"summary":"Get","operationId":"texts_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"delete":{"tags":["Texts"],"summary":"Delete","operationId":"texts_delete","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/DeleteResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos":{"post":{"tags":["Videos"],"summary":"Create","description":"# Video Models\nExternal models proxy to provider APIs; local models run on your GPU.\n\n| Model | Provider | External | Queue | Modes | Description |\n|-------|----------|:--------:|:-----:|-------|-------------|\n| ltx-video | local | No | gpu | first-last-image, image-to-video, text-to-video, video-to-video | Fast but more limited video generation model. Good for quick iterations and less complex scenes. |\n| wan-2 | local | No | gpu | first-last-image, image-to-video, text-to-video, video-to-video | Wan 2.2, quality open-source video generation model. Will fall back to Wan VACE 2.1 for video-to-video. |\n| runway-gen-4 | runway | Yes | cpu | image-to-video | Runway Gen-4 general video generation fast but limited. |\n| runway-act-two | runway | Yes | cpu | video-to-video | Matches animation from a reference video to a character reference image. |\n| runway-upscale | runway | Yes | cpu | video-to-video | Video upscaling model. |\n| runway-gen-4-aleph | runway | Yes | cpu | video-to-video | Aleph can enhance/alter existing video and use image references. |\n| bytedance-seedance-1 | replicate | Yes | cpu | first-last-image, image-to-video, text-to-video | Seedance-1 flagship model. Great all rounder. Supports high_quality variant. |\n| kwaivgi-kling-2 | replicate | Yes | cpu | first-last-image, image-to-video, text-to-video | Kling 2.5 flagship model. Great at first-last frame coherence. |\n| google-veo-3 | replicate | Yes | cpu | first-last-image, image-to-video, text-to-video | VEO-3.1 flagship model. Expensive. |\n| openai-sora-2 | replicate | Yes | cpu | image-to-video, text-to-video | Sora 2 openai flagship model. Expensive and not great at image-to-video. |\n| minimax-hailuo-2 | replicate | Yes | cpu | image-to-video, text-to-video | Hailuo-2.3 great physics understanding. |","operationId":"videos_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/videos/models":{"get":{"tags":["Videos"],"summary":"List video models","operationId":"videos_list_models","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoModelsResponse"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/videos/{id}":{"get":{"tags":["Videos"],"summary":"Get","operationId":"videos_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"delete":{"tags":["Videos"],"summary":"Delete","operationId":"videos_delete","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/DeleteResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/":{"get":{"summary":"Root","operationId":"root__get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}}},"components":{"schemas":{"DeleteResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id","description":"ID of the task"},"status":{"$ref":"#/components/schemas/TaskStatus","description":"Status of the task after deletion attempt"},"message":{"type":"string","title":"Message","description":"Additional information about the deletion result"}},"type":"object","required":["id","status","message"],"title":"DeleteResponse"},"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"ImageCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"}},"type":"object","required":["id","status"],"title":"ImageCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"ImageModelsResponse":{"properties":{"models":{"additionalProperties":{"$ref":"#/components/schemas/ImagesModelInfo"},"propertyNames":{"enum":["sd-xl","sd-3","flux-1","qwen-image","depth-anything-2","segment-anything-2","real-esrgan-x4","gpt-image-1","runway-gen4-image","flux-1-pro","topazlabs-upscale","google-gemini-2","bytedance-seedream-4"]},"type":"object","title":"Models"}},"type":"object","required":["models"],"title":"ImageModelsResponse"},"ImageRequest":{"properties":{"model":{"type":"string","enum":["sd-xl","sd-3","flux-1","qwen-image","depth-anything-2","segment-anything-2","real-esrgan-x4","gpt-image-1","runway-gen4-image","flux-1-pro","topazlabs-upscale","google-gemini-2","bytedance-seedream-4"],"title":"Model"},"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Detailed, 8k, photorealistic"},"height":{"type":"integer","title":"Height","default":720},"width":{"type":"integer","title":"Width","default":1280},"seed":{"type":"integer","title":"Seed","default":42},"strength":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Strength","description":"How strongly to follow the input image when transforming it (image-to-image/inpainting only). Ignored for text-to-image.","default":0.5},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 string image. If provided (and no mask), runs image-to-image using this as the starting point. PNG/JPEG recommended. Combine with prompt to guide the transformation."},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Base64 string image mask for inpainting. Must be provided together with 'image'. Non-zero/opaque regions indicate areas to modify. Triggers inpainting when supported."},"references":{"items":{"$ref":"#/components/schemas/References"},"type":"array","title":"References","description":"Optional control/adapters (style/depth/canny/pose/etc.) applied across models when supported."},"high_quality":{"type":"boolean","title":"High Quality","description":"Use higher quality models and steps when available. May increase cost/latency. For example some external models have pro variants.","default":false}},"type":"object","required":["model"],"title":"ImageRequest"},"ImageResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"},"result":{"anyOf":[{"$ref":"#/components/schemas/ImageWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"ImageResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"ImageWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"ImageWorkerResponse"},"ImagesModelInfo":{"properties":{"provider":{"type":"string","enum":["local","openai","replicate","runway"],"title":"Provider","description":"Source/provider identifier"},"external":{"type":"boolean","title":"External","description":"True if the model is invoked via an external API"},"supported_modes":{"items":{"type":"string","enum":["text-to-image","image-to-image","inpainting"]},"type":"array","uniqueItems":true,"title":"Supported Modes"},"references":{"type":"boolean","title":"References","default":false},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description"},"high_quality_variant":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"High Quality Variant","description":"Has a higher quality / pro variant. This can increase cost/latency.","default":false}},"type":"object","required":["provider","external"],"title":"ImagesModelInfo"},"References":{"properties":{"mode":{"type":"string","enum":["style","style-plus","face","depth","canny","pose"],"title":"Mode"},"strength":{"type":"number","title":"Strength","default":0.5},"image":{"type":"string","contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string"},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Optional Base64 image string"}},"type":"object","required":["mode","image"],"title":"References"},"TaskStatus":{"type":"string","enum":["PENDING","RECEIVED","STARTED","SUCCESS","FAILURE","RETRY","REVOKED","REJECTED","IGNORED"],"title":"TaskStatus"},"TextCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"}},"type":"object","required":["id","status"],"title":"TextCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"TextModelsResponse":{"properties":{"models":{"additionalProperties":{"$ref":"#/components/schemas/TextsModelInfo"},"propertyNames":{"enum":["qwen-2","gpt-4o","gpt-4","gpt-5"]},"type":"object","title":"Models"}},"type":"object","required":["models"],"title":"TextModelsResponse"},"TextRequest":{"properties":{"model":{"type":"string","enum":["qwen-2","gpt-4o","gpt-4","gpt-5"],"title":"Model","description":"model","default":"qwen-2"},"prompt":{"type":"string","title":"Prompt","description":"Prompt text","default":""},"system_prompt":{"type":"string","title":"System Prompt","description":"System prompt","default":"You are a helpful AI assistant specialized in visual effects, filmmaking, image generation, and creative workflows. You excel at analyzing images and videos, describing visual content, and generating detailed prompts for AI image/video generation models. When given images or videos, provide clear, detailed descriptions focusing on visual elements, composition, lighting, style, and technical aspects. When asked to create prompts, generate specific, detailed descriptions that would work well with AI generation models like Flux, Runway, or Stable Diffusion. Provide concise, actionable responses optimized for creative production pipelines. Do not ask for clarification - provide the best possible response based on the given input. Do not describe what you are doing or ask follow up questions.Use any images or videos provided in the conversation to inform your responses."},"images":{"items":{"type":"string"},"type":"array","title":"Images","description":"Image references","default":[]},"videos":{"items":{"type":"string"},"type":"array","title":"Videos","description":"Video references","default":[]}},"type":"object","title":"TextRequest"},"TextResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"},"result":{"anyOf":[{"$ref":"#/components/schemas/TextWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"TextResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"response":"This is a response from the model"},"status":"SUCCESS"}},"TextWorkerResponse":{"properties":{"response":{"type":"string","title":"Response"}},"type":"object","required":["response"],"title":"TextWorkerResponse"},"TextsModelInfo":{"properties":{"provider":{"type":"string","enum":["local","openai"],"title":"Provider","description":"Source/provider identifier"},"external":{"type":"boolean","title":"External","description":"True if the model is invoked via an external API"},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description"}},"type":"object","required":["provider","external"],"title":"TextsModelInfo"},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"},"VideoCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"}},"type":"object","required":["id","status"],"title":"VideoCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"VideoModelsResponse":{"properties":{"models":{"additionalProperties":{"$ref":"#/components/schemas/VideosModelInfo"},"propertyNames":{"enum":["ltx-video","wan-2","runway-gen-4","runway-act-two","runway-upscale","runway-gen-4-aleph","bytedance-seedance-1","kwaivgi-kling-2","google-veo-3","openai-sora-2","minimax-hailuo-2"]},"type":"object","title":"Models"}},"type":"object","required":["models"],"title":"VideoModelsResponse"},"VideoRequest":{"properties":{"model":{"type":"string","enum":["ltx-video","wan-2","runway-gen-4","runway-act-two","runway-upscale","runway-gen-4-aleph","bytedance-seedance-1","kwaivgi-kling-2","google-veo-3","openai-sora-2","minimax-hailuo-2"],"title":"Model"},"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Slow camera zoom in, 4k, high quality, cinematic, realistic"},"height":{"type":"integer","title":"Height","default":480},"width":{"type":"integer","title":"Width","default":854},"num_frames":{"type":"integer","maximum":250.0,"minimum":24.0,"title":"Num Frames","description":"Preferred number of frames to generate. External models will round to the nearest supported duration (e.g., 5s or 10s intervals). Values above 100 frames will automatically use the next available duration range.","default":48},"seed":{"type":"integer","title":"Seed","default":42},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string used for image-to-video conditioning or reference."},"last_image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Last Image","description":"Optional Base64 image string for the last frame guidance in image-to-video generation (requires image)."},"video":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"video/*","title":"Video","description":"Optional Base64 video string for video-to-video transformation or upscaling."},"high_quality":{"type":"boolean","title":"High Quality","description":"Use high quality model variant when available (may cost more and take longer). Will use higher steps in local models.","default":false}},"type":"object","required":["model"],"title":"VideoRequest"},"VideoResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"},"result":{"anyOf":[{"$ref":"#/components/schemas/VideoWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"VideoResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"VideoWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"VideoWorkerResponse"},"VideosModelInfo":{"properties":{"provider":{"type":"string","enum":["local","openai","replicate","runway"],"title":"Provider","description":"Source/provider identifier"},"external":{"type":"boolean","title":"External","description":"True if the model is invoked via an external API"},"supported_modes":{"items":{"type":"string","enum":["text-to-video","image-to-video","video-to-video","first-last-image"]},"type":"array","uniqueItems":true,"title":"Supported Modes"},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description"},"high_quality_variant":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"High Quality Variant","description":"Has a higher quality / pro variant. This can increase cost/latency.","default":false}},"type":"object","required":["provider","external"],"title":"VideosModelInfo"}},"securitySchemes":{"APIKeyHeader":{"type":"apiKey","in":"header","name":"Authorization"}}}}