{"openapi":"3.1.0","info":{"title":"Deferred Diffusion API","version":"0.1.0"},"paths":{"/api/images":{"post":{"tags":["Images"],"summary":"Create","description":"# Image Models\nExternal models proxy to provider APIs; local models run on your GPU.\n\n| Model | Provider | External | Queue | Modes | References | Description |\n|-------|----------|:--------:|:-----:|-------|:----------:|-------------|\n| sd-xl | local | No | gpu | image_to_image, inpainting, text_to_image | ✓ | Stable Diffusion XL variant with broad adapter/control support. |\n| sd-3 | local | No | gpu | image_to_image, inpainting, text_to_image | ✗ | Stable Diffusion 3.5 for complex compositions. |\n| flux-1 | local | No | gpu | image_to_image, inpainting, text_to_image | ✓ | FLUX dev model (Krea tuned). Uses Kontext for img2img, Fill for inpainting. |\n| qwen-image | local | No | gpu | image_to_image, inpainting, text_to_image | ✓ | Qwen image generation and manipulation. |\n| depth-anything-2 | local | No | gpu | image_to_image | ✗ | Depth estimation pipeline. |\n| segment-anything-2 | local | No | gpu | image_to_image | ✗ | Segmentation pipeline. |\n| gpt-image-1 | openai | Yes | cpu | image_to_image, inpainting, text_to_image | ✓ | OpenAI image model. |\n| runway-gen4-image | runway | Yes | cpu | image_to_image, text_to_image | ✓ | Runway Gen-4 image model. |\n| flux-1-pro | replicate | Yes | cpu | image_to_image, inpainting, text_to_image | ✗ | FLUX 1.1 Pro variants via external provider. |\n| topazlabs-upscale | replicate | Yes | cpu | image_to_image | ✗ | Topaz upscale model. |\n| google-gemini-2 | replicate | Yes | cpu | image_to_image, text_to_image | ✓ | Gemini multimodal image model. |\n| bytedance-seedream-4 | replicate | Yes | cpu | image_to_image, text_to_image | ✓ | Seedream image-to-image context model. |","operationId":"images_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/images/models":{"get":{"tags":["Images"],"summary":"List image models","operationId":"images_list_models","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"mode","in":"query","required":false,"schema":{"anyOf":[{"enum":["text_to_image","image_to_image","inpainting"],"type":"string"},{"type":"null"}],"title":"Mode"}},{"name":"external","in":"query","required":false,"schema":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"External"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageModelsResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/images/{id}":{"get":{"tags":["Images"],"summary":"Get","operationId":"images_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/texts":{"post":{"tags":["Texts"],"summary":"Create","description":"# Generate text using various language models.\n- External models are processed through their respective APIs.\n- Temperature controls randomness: lower values (0.1-0.3) for focused responses, higher values (0.7-1.0) for creative output.\n- Messages support conversation context with role-based structure (system, user, assistant).\n- Image and video references can be included for multimodal processing (where supported).\n# Local Models\n\n## qwen-2\n\nQwen-2 is a high-performance language model optimized for text generation and conversation. Excels at reasoning, creative writing, and multi-turn conversations.\n\n# External Models\n\n## gpt-4o\n\nOpenAI's GPT-4o model with enhanced multimodal capabilities. (mini variant)\n\n## gpt-4\n\nOpenAI's GPT-4 model with advanced reasoning capabilities. (4.1 mini variant)\n\n## gpt-5\n\nOpenAI's latest GPT-5 model with cutting-edge performance across all text generation tasks. (mini variant)","operationId":"texts_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/texts/{id}":{"get":{"tags":["Texts"],"summary":"Get","operationId":"texts_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos":{"post":{"tags":["Videos"],"summary":"Create","description":"# Video Models\nExternal models proxy to provider APIs; local models run on your GPU.\n\n| Model | Provider | External | Queue | Modes | Description |\n|-------|----------|:--------:|:-----:|-------|-------------|\n| ltx-video | local | No | gpu | first_last_frame, image_to_video, text_to_video, video_to_video | Fast but more limited video generation model. Good for quick iterations and less complex scenes. |\n| wan-2 | local | No | gpu | first_last_frame, image_to_video, text_to_video, video_to_video | Wan 2.2, quality open-source video generation model. Good motion coherence for varied scenes. |\n| runway-gen-4 | runway | Yes | cpu | image_to_video, text_to_video | Runway Gen-4 general video generation (text/image to video). |\n| runway-act-two | runway | Yes | cpu | image_to_video, text_to_video, video_to_video | Updates an input video with a reference image (image+video to video). |\n| runway-upscale | runway | Yes | cpu | video_to_video | Video upscaling model (video-to-video). |\n| runway-gen-4-aleph | runway | Yes | cpu | first_last_frame, image_to_video, text_to_video, video_to_video | Aleph variant: can enhance/alter existing video and use image references. |\n| bytedance-seedance-1 | replicate | Yes | cpu | image_to_video, text_to_video | Seedance-1 fast general video generation. |\n| kwaivgi-kling-2 | replicate | Yes | cpu | image_to_video, text_to_video | Kling V2 high-quality text/image to video generation. |\n| google-veo-3 | replicate | Yes | cpu | image_to_video, text_to_video | VEO-3 flagship model. Supports high_quality variant. |\n| openai-sora-2 | replicate | Yes | cpu | image_to_video, text_to_video | Sora 2 high-end text/image to video generation. Supports high_quality variant. |\n| minimax-hailuo-2 | replicate | Yes | cpu | text_to_video | Hailuo-2.3 text-to-video with multiple duration/resolution options. |","operationId":"videos_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/videos/models":{"get":{"tags":["Videos"],"summary":"List video models","operationId":"videos_list_models","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"mode","in":"query","required":false,"schema":{"anyOf":[{"enum":["text_to_video","image_to_video","video_to_video","first_last_frame"],"type":"string"},{"type":"null"}],"title":"Mode"}},{"name":"external","in":"query","required":false,"schema":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"External"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoModelsResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos/{id}":{"get":{"tags":["Videos"],"summary":"Get","operationId":"videos_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/":{"get":{"summary":"Root","operationId":"root__get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}}},"components":{"schemas":{"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"ImageCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"}},"type":"object","required":["id","status"],"title":"ImageCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"ImageModelsResponse":{"properties":{"models":{"additionalProperties":{"$ref":"#/components/schemas/ImagesModelInfo"},"propertyNames":{"enum":["sd-xl","sd-3","flux-1","qwen-image","depth-anything-2","segment-anything-2","real-esrgan-x4","gpt-image-1","runway-gen4-image","flux-1-pro","topazlabs-upscale","google-gemini-2","bytedance-seedream-4"]},"type":"object","title":"Models"}},"type":"object","required":["models"],"title":"ImageModelsResponse"},"ImageRequest":{"properties":{"model":{"type":"string","enum":["sd-xl","sd-3","flux-1","qwen-image","depth-anything-2","segment-anything-2","real-esrgan-x4","gpt-image-1","runway-gen4-image","flux-1-pro","topazlabs-upscale","google-gemini-2","bytedance-seedream-4"],"title":"Model"},"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Detailed, 8k, photorealistic"},"height":{"type":"integer","title":"Height","default":720},"width":{"type":"integer","title":"Width","default":1280},"seed":{"type":"integer","title":"Seed","default":42},"strength":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Strength","description":"How strongly to follow the input image when transforming it (image-to-image/inpainting only). Ignored for text-to-image.","default":0.5},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 string image. If provided (and no mask), runs image-to-image using this as the starting point. PNG/JPEG recommended. Combine with prompt to guide the transformation."},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Base64 string image mask for inpainting. Must be provided together with 'image'. Non-zero/opaque regions indicate areas to modify. Triggers inpainting when supported."},"references":{"items":{"$ref":"#/components/schemas/References"},"type":"array","title":"References","description":"Optional control/adapters (style/depth/canny/pose/etc.) applied across models when supported."},"high_quality":{"type":"boolean","title":"High Quality","description":"Use higher quality models and steps when available. May increase cost/latency. For example some external models have pro variants.","default":false}},"type":"object","required":["model"],"title":"ImageRequest"},"ImageResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"},"result":{"anyOf":[{"$ref":"#/components/schemas/ImageWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"ImageResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"ImageWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"ImageWorkerResponse"},"ImagesModelInfo":{"properties":{"provider":{"type":"string","enum":["local","openai","replicate","runway"],"title":"Provider","description":"Source/provider identifier"},"external":{"type":"boolean","title":"External","description":"True if the model is invoked via an external API"},"supported_modes":{"items":{"type":"string","enum":["text_to_image","image_to_image","inpainting"]},"type":"array","uniqueItems":true,"title":"Supported Modes"},"references":{"type":"boolean","title":"References","default":false},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description"}},"type":"object","required":["provider","external"],"title":"ImagesModelInfo"},"MessageContent":{"properties":{"type":{"type":"string","title":"Type"},"text":{"type":"string","title":"Text","default":""}},"type":"object","required":["type"],"title":"MessageContent"},"MessageItem":{"properties":{"role":{"type":"string","title":"Role"},"content":{"items":{"$ref":"#/components/schemas/MessageContent"},"type":"array","title":"Content"}},"type":"object","required":["role","content"],"title":"MessageItem"},"References":{"properties":{"mode":{"type":"string","enum":["style","style-plus","face","depth","canny","pose"],"title":"Mode"},"strength":{"type":"number","title":"Strength","default":0.5},"image":{"type":"string","contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string"},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Optional Base64 image string"}},"type":"object","required":["mode","image"],"title":"References"},"TextCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"}},"type":"object","required":["id","status"],"title":"TextCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"TextRequest":{"properties":{"model":{"type":"string","enum":["qwen-2","gpt-4o","gpt-4","gpt-5"],"title":"Model","description":"model","default":"qwen-2"},"temperature":{"type":"number","title":"Temperature","default":0.7},"seed":{"type":"integer","title":"Seed","default":42},"messages":{"items":{"$ref":"#/components/schemas/MessageItem"},"type":"array","title":"Messages","description":"List of messages","default":[]},"images":{"items":{"type":"string"},"type":"array","title":"Images","description":"Image references","default":[]},"videos":{"items":{"type":"string"},"type":"array","title":"Videos","description":"Video references","default":[]}},"type":"object","title":"TextRequest"},"TextResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"},"result":{"anyOf":[{"$ref":"#/components/schemas/TextWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"TextResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"chain_of_thought":["Step 1","Step 2","Conclusion"],"response":"This is a response from the model"},"status":"SUCCESS"}},"TextWorkerResponse":{"properties":{"response":{"type":"string","title":"Response"},"chain_of_thought":{"items":{},"type":"array","title":"Chain Of Thought"}},"type":"object","required":["response","chain_of_thought"],"title":"TextWorkerResponse"},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"},"VideoCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"}},"type":"object","required":["id","status"],"title":"VideoCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"VideoModelsResponse":{"properties":{"models":{"additionalProperties":{"$ref":"#/components/schemas/VideosModelInfo"},"propertyNames":{"enum":["ltx-video","wan-2","runway-gen-4","runway-act-two","runway-upscale","runway-gen-4-aleph","bytedance-seedance-1","kwaivgi-kling-2","google-veo-3","openai-sora-2","minimax-hailuo-2"]},"type":"object","title":"Models"}},"type":"object","required":["models"],"title":"VideoModelsResponse"},"VideoRequest":{"properties":{"model":{"type":"string","enum":["ltx-video","wan-2","runway-gen-4","runway-act-two","runway-upscale","runway-gen-4-aleph","bytedance-seedance-1","kwaivgi-kling-2","google-veo-3","openai-sora-2","minimax-hailuo-2"],"title":"Model"},"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Slow camera zoom in, 4k, high quality, cinematic, realistic"},"height":{"type":"integer","title":"Height","default":480},"width":{"type":"integer","title":"Width","default":854},"num_frames":{"type":"integer","title":"Num Frames","default":48},"seed":{"type":"integer","title":"Seed","default":42},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string used for image-to-video conditioning or reference."},"last_image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Last Image","description":"Optional Base64 image string for the last frame guidance in image-to-video generation (requires image)."},"video":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"video/*","title":"Video","description":"Optional Base64 video string for video-to-video transformation or upscaling."},"high_quality":{"type":"boolean","title":"High Quality","description":"Use high quality model variant when available (may cost more and take longer). Will use higher steps in local models.","default":false}},"type":"object","required":["model"],"title":"VideoRequest"},"VideoResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"},"result":{"anyOf":[{"$ref":"#/components/schemas/VideoWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"VideoResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"VideoWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"VideoWorkerResponse"},"VideosModelInfo":{"properties":{"provider":{"type":"string","enum":["local","openai","replicate","runway"],"title":"Provider","description":"Source/provider identifier"},"external":{"type":"boolean","title":"External","description":"True if the model is invoked via an external API"},"supported_modes":{"items":{"type":"string","enum":["text_to_video","image_to_video","video_to_video","first_last_frame"]},"type":"array","uniqueItems":true,"title":"Supported Modes"},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description"}},"type":"object","required":["provider","external"],"title":"VideosModelInfo"}},"securitySchemes":{"APIKeyHeader":{"type":"apiKey","in":"header","name":"Authorization"}}}}