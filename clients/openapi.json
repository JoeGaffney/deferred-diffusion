{"openapi":"3.1.0","info":{"title":"API","version":"0.1.0"},"paths":{"/api/images/local/{model}":{"post":{"tags":["Images"],"summary":"Create Local","description":"# Generate images using various diffusion models.\n- External models are processed through their respective APIs.\n- Local models are processed on your own GPU workers.\n- ControlNets and Adapters are unified as **references**.\n## sd-xl\n\nStable Diffusion XL variant supports the most control nets and IP adapters. It excels at generating high-quality, detailed images with complex prompts and multiple subjects.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✓\n\n## sd-3\n\nStable Diffusion 3.5 offers superior prompt understanding and composition. Excels at complex scenes, concept art, and handling multiple subjects with accurate interactions.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✗\n\n## flux-1\n\nFLUX Krea model is flux-1 dev trained with opinions from krea for more photorealistic results. Will use flux Kontext for image to image and flux fill for inpainting.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✓\n\n## qwen-image\n\nQwen model specializes in generating high-quality images from textual descriptions. It excels at understanding nuanced prompts and delivering detailed visuals.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✓\n\n## depth-anything-2\n\nAdvanced depth estimation model. Creates high-quality depth maps from any image for 3D visualization, AR applications, and as input for ControlNet pipelines.\n- **Text (text-to-image):** ✗\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✗\n\n## segment-anything-2\n\nState-of-the-art image segmentation model. Precisely identifies and segments objects, people, and features for compositing, editing, and analysis.\n- **Text (text-to-image):** ✗\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✗","operationId":"images_create_local","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["sd-xl","sd-3","flux-1","qwen-image","depth-anything-2","segment-anything-2","real-esrgan-x4"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/images/external/{model}":{"post":{"tags":["Images"],"summary":"Create External","description":"# Generate images using various diffusion models.\n- External models are processed through their respective APIs.\n- Local models are processed on your own GPU workers.\n- ControlNets and Adapters are unified as **references**.\n## gpt-image-1\n\nOpenAI's advanced image generation model with exceptional understanding of complex prompts. Excels at photorealistic imagery, accurate object rendering, and following detailed instructions.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✓\n\n## runway-gen4-image\n\nRunway's Gen-4 image model delivering high-fidelity results with strong coherence. Particularly good at combinging multiple references into a single, cohesive image.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✓\n\n## flux-1-pro\n\nPro variants of FLUX 1.1 with enhanced capabilities. Will use flux Kontext pro for image to image and flux fill pro for inpainting.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✓\n- **References (controlnets and adapters):** ✗\n\n## topazlabs-upscale\n\nTopaz Labs' advanced image upscaling model. Specializes in enhancing image resolution while preserving fine details and textures, ideal for professional photography and print work.\n- **Text (text-to-image):** ✗\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✗\n\n## google-gemini-2\n\nGoogle's Gemini 2.5 model for advanced image generation and manipulation. Aka nano bannana\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✓\n\n## bytedance-seedream-4\n\nSupreme image to image context model from Bytedance. Excels at transforming input images based on textual prompts while maintaining core elements of the original image.\n- **Text (text-to-image):** ✓\n- **Image (image-to-image):** ✓\n- **Mask (inpainting):** ✗\n- **References (controlnets and adapters):** ✓","operationId":"images_create_external","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["gpt-image-1","runway-gen4-image","flux-1-pro","topazlabs-upscale","google-gemini-2","bytedance-seedream-4"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/images/{id}":{"get":{"tags":["Images"],"summary":"Get","operationId":"images_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/texts/local/{model}":{"post":{"tags":["Texts"],"summary":"Create Local","description":"# Generate text using various language models.\n- External models are processed through their respective APIs.\n- Temperature controls randomness: lower values (0.1-0.3) for focused responses, higher values (0.7-1.0) for creative output.\n- Messages support conversation context with role-based structure (system, user, assistant).\n- Image and video references can be included for multimodal processing (where supported).\n## qwen-2\n\nQwen-2 is a high-performance language model optimized for text generation and conversation. Excels at reasoning, creative writing, and multi-turn conversations.","operationId":"texts_create_local","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"const":"qwen-2","type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/texts/external/{model}":{"post":{"tags":["Texts"],"summary":"Create External","description":"# Generate text using various language models.\n- External models are processed through their respective APIs.\n- Temperature controls randomness: lower values (0.1-0.3) for focused responses, higher values (0.7-1.0) for creative output.\n- Messages support conversation context with role-based structure (system, user, assistant).\n- Image and video references can be included for multimodal processing (where supported).\n## gpt-4o\n\nOpenAI's GPT-4o model with enhanced multimodal capabilities. (mini variant)\n\n## gpt-4\n\nOpenAI's GPT-4 model with advanced reasoning capabilities. (4.1 mini variant)\n\n## gpt-5\n\nOpenAI's latest GPT-5 model with cutting-edge performance across all text generation tasks. (mini variant)","operationId":"texts_create_external","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["gpt-4o","gpt-4","gpt-5"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/texts/{id}":{"get":{"tags":["Texts"],"summary":"Get","operationId":"texts_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos/local/{model}":{"post":{"tags":["Videos"],"summary":"Create Local","description":"# Generate videos using various diffusion models.\n\n# Local Models\n\n### ltx-video\n\nFast but more limted video generation model. Good for quick iterations and less complex scenes.\n\n\n### wan-2\n\nWan 2.2, best open-source video generation model. Good quality and motion coherence for a variety of scenes.","operationId":"videos_create_local","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["ltx-video","wan-2"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos/external/{model}":{"post":{"tags":["Videos"],"summary":"Create External","description":"# Generate videos using various diffusion models.\n\n# External Models\n\n### bytedance-seedance-1\n\nByteDance's Seedance-1 model, Pretty strong overall and quite fast. Good for a variety of video generation tasks with decent quality and speed.\n\n\n### google-veo-3\n\nGoogle's VEO-3 model, high end flagship model. Supports high_quality parameter for slower but higher quality variant.\n\n\n### kwaivgi-kling-2\n\nKling V2 model by kwaivgi, designed for high-quality video generation from text prompts. Known for its ability to create detailed and coherent video sequences.\n\n\n### minimax-hailuo-2\n\nMinimax's Hailuo-2.3 model, advanced video generation with support for both 6s and 10s duration videos. Supports 768p and 1080p resolutions with prompt optimization capabilities.\n\n\n### openai-sora-2\n\nOpenAI's Sora 2 model, high-end video generation model known for producing high-quality and realistic videos from text prompts. Supports high_quality parameter for pro variant. Ideal for professional-grade video content creation.\n\n\n### runway-act-two\n\nRunway's Act Two model updates a video with reference image. Ideal for enhancing existing footage with new visual elements while maintaining original motion and style.\n\n\n### runway-gen-4\n\nRunway's latest Gen-4 showing it's age fast computer time. Good for a variety of video generation tasks with improved quality over Gen-3.\n\n\n### runway-gen-4-aleph\n\nRunway's Gen-4 Aleph model, takes in video input as well as images and can enhance or change the video. Or even generate new video content based on the input images and video. Ideal for creative video transformations and enhancements.\n\n\n### runway-upscale\n\nRunway's Upscale model for high-quality video upscaling. Utilizes advanced techniques to enhance video resolution and detail.","operationId":"videos_create_external","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"model","in":"path","required":true,"schema":{"enum":["runway-gen-4","runway-act-two","runway-upscale","runway-gen-4-aleph","bytedance-seedance-1","kwaivgi-kling-2","google-veo-3","openai-sora-2","minimax-hailuo-2"],"type":"string","title":"Model"}}],"requestBody":{"required":true,"content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoRequest"}}}},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos/{id}":{"get":{"tags":["Videos"],"summary":"Get","operationId":"videos_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/":{"get":{"summary":"Root","operationId":"root__get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}}},"components":{"schemas":{"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"ImageCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"}},"type":"object","required":["id","status"],"title":"ImageCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"ImageRequest":{"properties":{"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Detailed, 8k, photorealistic"},"height":{"type":"integer","title":"Height","default":720},"width":{"type":"integer","title":"Width","default":1280},"seed":{"type":"integer","title":"Seed","default":42},"strength":{"type":"number","title":"Strength","default":0.5},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Optional Base64 image string"},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Optional Base64 image string"},"references":{"items":{"$ref":"#/components/schemas/References"},"type":"array","title":"References","default":[]},"high_quality":{"type":"boolean","title":"High Quality","description":"Use high quality model variant when available (may cost more and take longer). Will use higher steps in local models.","default":false}},"type":"object","title":"ImageRequest"},"ImageResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"},"result":{"anyOf":[{"$ref":"#/components/schemas/ImageWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"ImageResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"ImageWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"ImageWorkerResponse"},"MessageContent":{"properties":{"type":{"type":"string","title":"Type"},"text":{"type":"string","title":"Text","default":""}},"type":"object","required":["type"],"title":"MessageContent"},"MessageItem":{"properties":{"role":{"type":"string","title":"Role"},"content":{"items":{"$ref":"#/components/schemas/MessageContent"},"type":"array","title":"Content"}},"type":"object","required":["role","content"],"title":"MessageItem"},"References":{"properties":{"mode":{"type":"string","enum":["style","style-plus","face","depth","canny","pose"],"title":"Mode"},"strength":{"type":"number","title":"Strength","default":0.5},"image":{"type":"string","contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string"},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Optional Base64 image string"}},"type":"object","required":["mode","image"],"title":"References"},"TextCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"}},"type":"object","required":["id","status"],"title":"TextCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"TextRequest":{"properties":{"temperature":{"type":"number","title":"Temperature","default":0.7},"seed":{"type":"integer","title":"Seed","default":42},"messages":{"items":{"$ref":"#/components/schemas/MessageItem"},"type":"array","title":"Messages","description":"List of messages","default":[]},"images":{"items":{"type":"string"},"type":"array","title":"Images","description":"Image references","default":[]},"videos":{"items":{"type":"string"},"type":"array","title":"Videos","description":"Video references","default":[]}},"type":"object","title":"TextRequest"},"TextResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"},"result":{"anyOf":[{"$ref":"#/components/schemas/TextWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"TextResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"chain_of_thought":["Step 1","Step 2","Conclusion"],"response":"This is a response from the model"},"status":"SUCCESS"}},"TextWorkerResponse":{"properties":{"response":{"type":"string","title":"Response"},"chain_of_thought":{"items":{},"type":"array","title":"Chain Of Thought"}},"type":"object","required":["response","chain_of_thought"],"title":"TextWorkerResponse"},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"},"VideoCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"}},"type":"object","required":["id","status"],"title":"VideoCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"VideoRequest":{"properties":{"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Slow camera zoom in, 4k, high quality, cinematic, realistic"},"height":{"type":"integer","title":"Height","default":720},"width":{"type":"integer","title":"Width","default":1280},"num_frames":{"type":"integer","title":"Num Frames","default":48},"seed":{"type":"integer","title":"Seed","default":42},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string"},"last_image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Last Image","description":"Optional Base64 image string for the last image/frame in image-to-video generation"},"video":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"video/*","title":"Video","description":"Optional Base64 video string for video input"},"high_quality":{"type":"boolean","title":"High Quality","description":"Use high quality model variant when available (may cost more and take longer). Will use higher steps in local models.","default":false}},"type":"object","title":"VideoRequest"},"VideoResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"type":"string","title":"Status"},"result":{"anyOf":[{"$ref":"#/components/schemas/VideoWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"VideoResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"VideoWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"VideoWorkerResponse"}},"securitySchemes":{"APIKeyHeader":{"type":"apiKey","in":"header","name":"Authorization"}}}}