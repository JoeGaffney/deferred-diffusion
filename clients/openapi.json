{"openapi":"3.1.0","info":{"title":"API","version":"0.1.0"},"paths":{"/api/images":{"post":{"tags":["Images"],"summary":"Create","description":"# Image Models\nExternal models proxy to provider APIs; local models run on your GPU.\n\n| Model | Provider | External | Queue | Modes | References | Description |\n|-------|----------|:--------:|:-----:|-------|:----------:|-------------|\n| sd-xl | local | No | gpu | image-to-image, inpainting, text-to-image | ✓ | Stable Diffusion XL variant with broad adapter/control support. |\n| flux-1 | local | No | gpu | image-to-image, inpainting, text-to-image | ✓ | FLUX dev model (Krea tuned). Uses Kontext for img2img, Fill for inpainting. |\n| flux-2 | local | No | gpu | image-to-image, inpainting, text-to-image | ✓ | FLUX 2.0 dev model with edit capabilities. |\n| qwen-image | local | No | gpu | image-to-image, inpainting, text-to-image | ✓ | Qwen image generation and manipulation. |\n| depth-anything-2 | local | No | gpu | image-to-image | ✗ | Depth estimation pipeline. |\n| sam-2 | local | No | gpu | image-to-image | ✗ | Meta's SAM 2 Segmentation pipeline. |\n| sam-3 | local | No | gpu | image-to-image | ✗ | Meta's SAM 3 Segmentation pipeline. |\n| gpt-image-1 | openai | Yes | cpu | image-to-image, inpainting, text-to-image | ✓ | OpenAI image model. |\n| runway-gen4-image | replicate | Yes | cpu | image-to-image, text-to-image | ✓ | Runway Gen-4 image model. |\n| flux-1-pro | replicate | Yes | cpu | image-to-image, inpainting, text-to-image | ✗ | FLUX 1.1 Pro variants via external provider. |\n| topazlabs-upscale | replicate | Yes | cpu | image-to-image | ✗ | Topaz upscale model. |\n| google-gemini-2 | replicate | Yes | cpu | image-to-image, text-to-image | ✓ | Gemini multimodal image model. |\n| google-gemini-3 | replicate | Yes | cpu | image-to-image, text-to-image | ✓ | Gemini 3 Pro image model. |\n| bytedance-seedream-4 | replicate | Yes | cpu | image-to-image, text-to-image | ✓ | Seedream image-to-image context model. |","operationId":"images_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/images/models":{"get":{"tags":["Images"],"summary":"List image models","operationId":"images_list_models","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageModelsResponse"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/images/{id}":{"get":{"tags":["Images"],"summary":"Get","operationId":"images_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/ImageResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"delete":{"tags":["Images"],"summary":"Delete","operationId":"images_delete","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/DeleteResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/texts":{"post":{"tags":["Texts"],"summary":"Create","description":"# Text Models\nExternal models proxy to provider APIs; local models run on your GPU.\n\n| Model | Provider | External | Queue | Description |\n|-------|----------|:--------:|:-----:|-------------|\n| qwen-2 | local | No | gpu | Qwen-2 is a high-performance language model optimized for text generation and conversation. Excels at reasoning, creative writing, and multi-turn conversations. |\n| gpt-4o | openai | Yes | cpu | OpenAI's GPT-4o model with enhanced multimodal capabilities. (mini variant) |\n| gpt-4 | openai | Yes | cpu | OpenAI's GPT-4 model with advanced reasoning capabilities. (4.1 mini variant) |\n| gpt-5 | openai | Yes | cpu | OpenAI's latest GPT-5 model with cutting-edge performance across all text generation tasks. (mini variant) |","operationId":"texts_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/texts/models":{"get":{"tags":["Texts"],"summary":"List text models","operationId":"texts_list_models","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextModelsResponse"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/texts/{id}":{"get":{"tags":["Texts"],"summary":"Get","operationId":"texts_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/TextResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"delete":{"tags":["Texts"],"summary":"Delete","operationId":"texts_delete","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/DeleteResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/api/videos":{"post":{"tags":["Videos"],"summary":"Create","description":"# Video Models\nExternal models proxy to provider APIs; local models run on your GPU.\n\n| Model | Provider | External | Queue | Modes | Description |\n|-------|----------|:--------:|:-----:|-------|-------------|\n| ltx-video | local | No | gpu | first-last-image, image-to-video, text-to-video, video-to-video | Fast but more limited video generation model. Good for quick iterations and less complex scenes. |\n| wan-2 | local | No | gpu | first-last-image, image-to-video, text-to-video, video-to-video | Wan 2.2, quality open-source video generation model. Will fall back to Wan VACE 2.1 for video-to-video. |\n| runway-gen-4 | replicate | Yes | cpu | image-to-video, video-to-video | Runway Gen-4 family. Uses standard Gen-4 for image-to-video and Aleph variant for video-to-video. |\n| runway-upscale | replicate | Yes | cpu | video-to-video | Runway's video upscaling model. |\n| bytedance-seedance-1 | replicate | Yes | cpu | first-last-image, image-to-video, text-to-video | Seedance-1 flagship model. Great all rounder. |\n| kwaivgi-kling-2 | replicate | Yes | cpu | first-last-image, image-to-video, text-to-video | Kling 2.5 flagship model. Great at first-last frame coherence. |\n| google-veo-3 | replicate | Yes | cpu | first-last-image, image-to-video, text-to-video | VEO-3.1 flagship model. Expensive. |\n| openai-sora-2 | replicate | Yes | cpu | image-to-video, text-to-video | Sora 2 openai flagship model. Expensive and not great at image-to-video. |\n| minimax-hailuo-2 | replicate | Yes | cpu | image-to-video, text-to-video | Hailuo-2.3 great physics understanding. |","operationId":"videos_create","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoRequest"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoCreateResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/videos/models":{"get":{"tags":["Videos"],"summary":"List video models","operationId":"videos_list_models","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoModelsResponse"}}}}},"security":[{"APIKeyHeader":[]}]}},"/api/videos/{id}":{"get":{"tags":["Videos"],"summary":"Get","operationId":"videos_get","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/VideoResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}},"delete":{"tags":["Videos"],"summary":"Delete","operationId":"videos_delete","security":[{"APIKeyHeader":[]}],"parameters":[{"name":"id","in":"path","required":true,"schema":{"type":"string","format":"uuid","title":"Id"}}],"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{"$ref":"#/components/schemas/DeleteResponse"}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}},"/":{"get":{"summary":"Root","operationId":"root__get","responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}}}}}},"components":{"schemas":{"DeleteResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id","description":"ID of the task"},"status":{"$ref":"#/components/schemas/TaskStatus","description":"Status of the task after deletion attempt"},"message":{"type":"string","title":"Message","description":"Additional information about the deletion result"}},"type":"object","required":["id","status","message"],"title":"DeleteResponse"},"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"ImageCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"}},"type":"object","required":["id","status"],"title":"ImageCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"ImageModelsResponse":{"properties":{"models":{"additionalProperties":{"$ref":"#/components/schemas/ImagesModelInfo"},"propertyNames":{"enum":["sd-xl","flux-1","flux-2","qwen-image","depth-anything-2","sam-2","sam-3","real-esrgan-x4","gpt-image-1","runway-gen4-image","flux-1-pro","topazlabs-upscale","google-gemini-2","google-gemini-3","bytedance-seedream-4"]},"type":"object","title":"Models"}},"type":"object","required":["models"],"title":"ImageModelsResponse"},"ImageRequest":{"properties":{"model":{"type":"string","enum":["sd-xl","flux-1","flux-2","qwen-image","depth-anything-2","sam-2","sam-3","real-esrgan-x4","gpt-image-1","runway-gen4-image","flux-1-pro","topazlabs-upscale","google-gemini-2","google-gemini-3","bytedance-seedream-4"],"title":"Model"},"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Detailed, 8k, photorealistic"},"height":{"type":"integer","title":"Height","default":720},"width":{"type":"integer","title":"Width","default":1280},"seed":{"type":"integer","title":"Seed","default":42},"strength":{"type":"number","maximum":1.0,"minimum":0.0,"title":"Strength","description":"How strongly to follow the input image when transforming it (image-to-image/inpainting only). Ignored for text-to-image.","default":0.5},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 string image. If provided (and no mask), runs image-to-image using this as the starting point. PNG/JPEG recommended. Combine with prompt to guide the transformation."},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Base64 string image mask for inpainting. Must be provided together with 'image'. Non-zero/opaque regions indicate areas to modify. Triggers inpainting when supported."},"references":{"items":{"$ref":"#/components/schemas/References"},"type":"array","title":"References","description":"Optional control/adapters (style/depth/canny/pose/etc.) applied across models when supported."}},"type":"object","required":["model"],"title":"ImageRequest"},"ImageResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"},"result":{"anyOf":[{"$ref":"#/components/schemas/ImageWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"ImageResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"ImageWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"ImageWorkerResponse"},"ImagesModelInfo":{"properties":{"provider":{"type":"string","enum":["local","openai","replicate"],"title":"Provider","description":"Source/provider identifier"},"external":{"type":"boolean","title":"External","description":"True if the model is invoked via an external API"},"supported_modes":{"items":{"type":"string","enum":["text-to-image","image-to-image","inpainting"]},"type":"array","uniqueItems":true,"title":"Supported Modes"},"references":{"type":"boolean","title":"References","default":false},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description"}},"type":"object","required":["provider","external"],"title":"ImagesModelInfo"},"References":{"properties":{"mode":{"type":"string","enum":["style","style-plus","face","depth","canny","pose"],"title":"Mode"},"strength":{"type":"number","title":"Strength","default":0.5},"image":{"type":"string","contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string"},"mask":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Mask","description":"Optional Base64 image string"}},"type":"object","required":["mode","image"],"title":"References"},"SystemPrompt":{"type":"string","enum":["NONE","BASE","IMAGE_OPTIMIZER","VIDEO_OPTIMIZER","VIDEO_TRANSITION"],"title":"SystemPrompt"},"TaskStatus":{"type":"string","enum":["PENDING","RECEIVED","STARTED","SUCCESS","FAILURE","RETRY","REVOKED","REJECTED","IGNORED"],"title":"TaskStatus"},"TextCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"}},"type":"object","required":["id","status"],"title":"TextCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"TextModelsResponse":{"properties":{"models":{"additionalProperties":{"$ref":"#/components/schemas/TextsModelInfo"},"propertyNames":{"enum":["qwen-2","gpt-4o","gpt-4","gpt-5"]},"type":"object","title":"Models"}},"type":"object","required":["models"],"title":"TextModelsResponse"},"TextRequest":{"properties":{"model":{"type":"string","enum":["qwen-2","gpt-4o","gpt-4","gpt-5"],"title":"Model","description":"model","default":"qwen-2"},"prompt":{"type":"string","title":"Prompt","description":"Prompt text","default":""},"system_prompt":{"$ref":"#/components/schemas/SystemPrompt","description":"System prompt type. Options:\nNONE: Will use the model's default behavior.\n\nBASE: You are a helpful AI assistant specialized in visual effects, filmmaking, and creative workflows. You excel at analyzing images and videos, describing visual content in detail, and providing expert feedback. \nWhen analyzing visual content, focus on: composition and framing, lighting and color grading, camera work and movement, visual effects and technical quality, storytelling and mood, artistic style and influences. \nYou can: - Compare multiple images or videos and identify differences\n- Provide technical feedback on visual quality and composition\n- Suggest improvements for lighting, framing, or effects\n- Describe what you see in a clear, detailed manner\n- Answer questions about visual content and creative techniques\n\nProvide concise, actionable insights. Be direct and specific. Use any images or videos provided in the conversation to inform your responses. Do not ask for clarification—provide the best possible response based on the given input.\n\nIMAGE_OPTIMIZER: You are an expert AI image prompt optimizer. Write concise, vivid descriptions for models like Flux, Stable Diffusion, or Midjourney.\nDescribe in this order: primary subject and focal point, secondary elements and spatial relationships, setting and background, artistic style and medium, lighting and color palette, composition and camera perspective.\nDefault to photorealism unless a different style is requested. For photorealism, focus on realistic lighting, accurate materials, natural physics, believable proportions, and lifelike details.\nIf a reference image is provided:- For style transfer or img2img: describe desired changes and what to preserve\n- For inspiration: use it to inform mood, composition, or style, not literal replication\n\nUse technical terms, style markers, and quality tags only when relevant; do not force them into every prompt.\nOutput only the optimized prompt. No preamble, labels, or explanations. Max 500 words.\n\nVIDEO_OPTIMIZER: You are an expert AI video prompt optimizer. Write concise, cinematic descriptions for models like Runway, Pika, or Kling.\nDescribe in this order: core action and scene progression, camera movement and framing, environment, lighting, subject details, and pacing.\nDefault to photorealism and realistic physics unless a different style is requested. When realistic, focus on natural motion, believable physics, realistic lighting, and lifelike interactions.\nIf reference images are provided:- Single image: treat as the starting frame and describe how motion emerges\n- Multiple images: use only the first for the opening frame; focus on motion and progression\n- No images: rely on the text prompt\n\nUse technical terms (camera, timing, physics, lighting, quality) only when relevant; do not force them into every prompt.\nEmphasize motion and temporal flow. Be specific about realistic changes.\nOutput only the optimized prompt. No preamble, labels, or explanations. Max 500 words.\n\nVIDEO_TRANSITION: You are an expert AI video prompt optimizer for keyframe-to-keyframe video generation. Two reference images define start and end states—describe the journey between them.\nEstablish the starting state, describe the transformation and transition, camera movement, environment and lighting changes, and the arrival at the final state.\nDefault to photorealism and realistic physics unless context suggests otherwise. Emphasize natural, believable transitions and realistic motion.\nUse temporal markers and cinematic terms (e.g., match cut, morph, cross-dissolve, continuous motion) only if relevant; do not force them into every prompt.Quality markers (e.g., seamless transition, smooth motion, 4K, cinematic, photorealistic) are examples—use only when appropriate.\nOutput only the optimized prompt. No preamble, labels, or explanations. Max 500 words.\n","default":"BASE"},"images":{"items":{"type":"string"},"type":"array","title":"Images","description":"Image references","default":[]},"videos":{"items":{"type":"string"},"type":"array","title":"Videos","description":"Video references","default":[]}},"type":"object","title":"TextRequest"},"TextResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"},"result":{"anyOf":[{"$ref":"#/components/schemas/TextWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"TextResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"response":"This is a response from the model"},"status":"SUCCESS"}},"TextWorkerResponse":{"properties":{"response":{"type":"string","title":"Response"}},"type":"object","required":["response"],"title":"TextWorkerResponse"},"TextsModelInfo":{"properties":{"provider":{"type":"string","enum":["local","openai","replicate"],"title":"Provider","description":"Source/provider identifier"},"external":{"type":"boolean","title":"External","description":"True if the model is invoked via an external API"},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description"}},"type":"object","required":["provider","external"],"title":"TextsModelInfo"},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"},"VideoCreateResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"}},"type":"object","required":["id","status"],"title":"VideoCreateResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","status":"PENDING"}},"VideoModelsResponse":{"properties":{"models":{"additionalProperties":{"$ref":"#/components/schemas/VideosModelInfo"},"propertyNames":{"enum":["ltx-video","wan-2","runway-gen-4","runway-act-two","runway-upscale","bytedance-seedance-1","kwaivgi-kling-2","google-veo-3","openai-sora-2","minimax-hailuo-2"]},"type":"object","title":"Models"}},"type":"object","required":["models"],"title":"VideoModelsResponse"},"VideoRequest":{"properties":{"model":{"type":"string","enum":["ltx-video","wan-2","runway-gen-4","runway-act-two","runway-upscale","bytedance-seedance-1","kwaivgi-kling-2","google-veo-3","openai-sora-2","minimax-hailuo-2"],"title":"Model"},"prompt":{"type":"string","format":"multi_line","title":"Prompt","description":"Positive Prompt text","default":"Slow camera zoom in, 4k, high quality, cinematic, realistic"},"height":{"type":"integer","title":"Height","default":480},"width":{"type":"integer","title":"Width","default":854},"num_frames":{"type":"integer","maximum":250.0,"minimum":24.0,"title":"Num Frames","description":"Preferred number of frames to generate. External models will round to the nearest supported duration (e.g., 5s or 10s intervals). Values above 100 frames will automatically use the next available duration range.","default":48},"seed":{"type":"integer","title":"Seed","default":42},"image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Image","description":"Base64 image string used for image-to-video conditioning or reference."},"last_image":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"image/*","title":"Last Image","description":"Optional Base64 image string for the last frame guidance in image-to-video generation (requires image)."},"video":{"anyOf":[{"type":"string"},{"type":"null"}],"contentEncoding":"base64","contentMediaType":"video/*","title":"Video","description":"Optional Base64 video string for video-to-video transformation or upscaling."}},"type":"object","required":["model"],"title":"VideoRequest"},"VideoResponse":{"properties":{"id":{"type":"string","format":"uuid","title":"Id"},"status":{"$ref":"#/components/schemas/TaskStatus"},"result":{"anyOf":[{"$ref":"#/components/schemas/VideoWorkerResponse"},{"type":"null"}]},"error_message":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Error Message"}},"type":"object","required":["id","status"],"title":"VideoResponse","example":{"id":"9a34ab0a-9e9a-4b84-90f7-d8b30c59b6ae","result":{"base64_data":"iVBORw0KGgoAAAANSUhEUgAA..."},"status":"SUCCESS"}},"VideoWorkerResponse":{"properties":{"base64_data":{"type":"string","format":"base64","title":"Base64 Data"}},"type":"object","required":["base64_data"],"title":"VideoWorkerResponse"},"VideosModelInfo":{"properties":{"provider":{"type":"string","enum":["local","openai","replicate"],"title":"Provider","description":"Source/provider identifier"},"external":{"type":"boolean","title":"External","description":"True if the model is invoked via an external API"},"supported_modes":{"items":{"type":"string","enum":["text-to-video","image-to-video","video-to-video","first-last-image"]},"type":"array","uniqueItems":true,"title":"Supported Modes"},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description"}},"type":"object","required":["provider","external"],"title":"VideosModelInfo"}},"securitySchemes":{"APIKeyHeader":{"type":"apiKey","in":"header","name":"Authorization"}}}}